# -*- coding: utf-8 -*-
"""SIP7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUG5kmBxblKAn-FMFvQ6wJcI7ZBSq7xM
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import lines

def straight_line_hough(i, edgeI):
  thres = 150
  edgeH, edgeW = edgeI.shape[:2]
  
  distance = np.sqrt(edgeH**2 + edgeW**2)
  distanceRho = (distance/0.5) / 180

  ts = np.arange(0, 180)
  rs = np.arange(-distance, distance, step=distanceRho)

  cosTs = np.cos(np.deg2rad(ts))
  sinTs = np.sin(np.deg2rad(ts))
  accumulator = np.zeros((len(rs), len(rs)))

  fig, ax = plt.subplots(1, 3, figsize=(12,10))
  ax[0].imshow(i, cmap="gray")
  ax[0].set_title("Original")
  ax[1].imshow(edgeI, cmap="gray")
  ax[1].set_title("Edge im")
  ax[2].imshow(i, cmap="gray")
  ax[2].set_title("Lines detected")

  fig2, ax2 = plt.subplots(1)
  ax2.set_facecolor("k")
  ax2.set_title("Hough transform")

  for x in range(edgeH):
    for y in range(edgeW):
      if edgeI[x][y] != 0:
        p = [x - (edgeH / 2), y - (edgeW / 2)]
        xs = []
        ys = []
        for j in range(len(ts)):
          r = (p[1] * cosTs[j]) + (p[0] * sinTs[j])
          t = ts[j]
          rJ = np.argmin(np.abs(rs - r))
          accumulator[rJ][j] += 1
          xs.append(t)
          ys.append(r)
        ax2.plot(xs, ys, c="w", alpha=0.06)

  for x in range(accumulator.shape[0]):
    for y in range(accumulator.shape[1]):
      if accumulator[x][y] > thres:
        a = np.cos(np.deg2rad(ts[y]))
        b = np.sin(np.deg2rad(ts[y]))
        x0 = (a * rs[x]) + (edgeW / 2)
        y0 = (b * rs[x]) + (edgeH / 2)
        lS = [int(x0 + (-b * distance)), int(y0 + (a * distance))]
        lE = [int(x0 - (-b * distance)), int(y0 - (a * distance))]
        ax[2].add_line(lines.Line2D([lS[0], lE[0]], [lS[1], lE[1]]))

im = cv2.imread("/content/cross.png", 0)
b = cv2.GaussianBlur(im, (3,3), 1)
es = cv2.Canny(b, 100, 200)
es = cv2.dilate(es, cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)), iterations=1)
es = cv2.erode(es, cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)), iterations=1)
straight_line_hough(im, es)

import numpy as np

from skimage.transform import hough_line, hough_line_peaks

agls = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)
h, t, d = hough_line(im, theta=agls)

step = 0.5 * np.diff(t).mean()
d_step = 0.5 * np.diff(d).mean()
bs = [np.rad2deg(t[0] - step), np.rad2deg(t[-1] + step), d[-1] + d_step, d[0] - d_step]

fig, axes = plt.subplots(1, 3, figsize=(15, 6))
ax = axes.ravel()

ax[0].imshow(im, cmap="gray")
ax[0].set_title("Original")

ax[1].imshow(np.log(1 + h), extent=bs, cmap="gray")
ax[1].set_title("Scikits Hough transform")
ax[2].imshow(im, cmap="gray")
ax[2].set_title("Scikits lines detected")

for _, a, d in zip(*hough_line_peaks(h, t, d)):
  (x0, y0) = d * np.array([np.cos(a), np.sin(a)])
  xs = np.array(ax[2].get_xlim())
  ys = y0 + np.tan(a + np.pi/2) * xs
  ax[2].add_line(lines.Line2D(xs, ys))

#1.3
from skimage.transform import hough_circle, hough_circle_peaks
from skimage import feature, color
from skimage.draw import circle_perimeter
from scipy.spatial import distance

im = cv2.imread("/content/coins.png", 0)
eIm = feature.canny(im, sigma=2)

hRad = np.arange(10,40,2)
hRes = hough_circle(eIm, hRad)

accumulator, xC, yC, r = hough_circle_peaks(hRes, hRad, total_num_peaks=20)
mDis = 20

delMask = []

coordinates = list(zip(xC, yC))
for x in range(len(coordinates)):
  for y in range(x+1, len(coordinates)):
    if(distance.euclidean(coordinates[x], coordinates[y]) < mDis):
      delMask.append(y)

xs = np.delete(xC, np.unique(np.array(delMask)))
ys = np.delete(yC, np.unique(np.array(delMask)))

fig, ax = plt.subplots(1, figsize=(12,10))
colIm = color.gray2rgb(im)
for y, x, r in zip(xs, ys, r):
  circY, circX = circle_perimeter(x, y, r, shape=im.shape)
  colIm[circY, circX] = (200, 40, 40)

ax.imshow(colIm, cmap="gray")

import numpy

from tensorflow.keras import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, InputLayer
from tensorflow.keras.optimizers import Adam

## Configure the network

# batch_size to train
batch_size = 20 * 256
# number of output classes
nb_classes = 135
# number of epochs to train
nb_epoch = 400

# number of convolutional filters to use
nb_filters = 20
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 5

model = Sequential([
    InputLayer(input_shape=(29, 29, 1)),
    Conv2D(filters=nb_filters, kernel_size=nb_conv, activation='relu'),
    MaxPool2D(pool_size=(nb_pool, nb_pool)),
    Dropout(0.5),
    Conv2D(filters=nb_filters, kernel_size=nb_conv, activation='relu'),
    MaxPool2D(pool_size=(nb_pool, nb_pool)),
    Dropout(0.25),
    Flatten(),
    Dense(units=4000, activation='relu'),
    Dense(units=nb_classes, activation='softmax'),
])
    
optimizer = Adam(lr=1e-4, epsilon=1e-08)

model.compile(optimizer=optimizer,
             loss='categorical_crossentropy',
             metrics=['accuracy'])


## Train model - uncoment to perform the training yourself
#

#train = numpy.load('train.npz')
#x_train = train['x_train'].reshape((-1, 29, 29, 1))
#y_train = train['y_train']
#
#early_stopping = EarlyStopping(patience=10)
#history = model.fit(x_train, y_train, epochs=nb_epoch, batch_size=batch_size,
#                    callbacks=[early_stopping], validation_split=0.2)
#model.save_weights('keras.h5')

## Load the pretrained network
model.load_weights('keras.h5')

test = numpy.load('test.npz')
x_test = test['x_test']
y_test = test['y_test']

x_test = x_test.reshape(-1,29,29,1)

print(x_test[0].shape)

# Get accuracy
model.evaluate(
    x=x_test,
    y=y_test,
)

import matplotlib.pyplot as plt
test_image = plt.imread('1003_3_image.png')
seg_image = plt.imread('1003_3_seg.png')
plt.imshow(test_image)
plt.imshow(seg_image)

from sklearn.feature_extraction.image import extract_patches_2d
import math
import numpy as np
def create_patches(image, size=29):
    zero_pad = np.pad(image, math.floor(size/2), mode='constant', constant_values=0)
    patches = extract_patches_2d(zero_pad, (size,size))
    return patches
patches = create_patches(test_image)
patches = patches.reshape(256*256,29,29,1)
res = np.argmax(model.predict(patches*255), axis=-1)
len(res[res>0])
res = res.reshape(256,256)
plt.title('Predicted segmentation')
plt.imshow(res)
def dice(image, image2):
    sim_count = 0
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            if image[i,j] == image2[i,j]:
                sim_count += 1
    return (2 * sim_count) / (2*(image.shape[0]*image.shape[1]))
dice(res,seg_image)
from xgboost import XGBClassifier
train = numpy.load('train.npz')
x_train = train['x_train']
y_train = train['y_train']
x_train=x_train.reshape(210704, 29*29)
y_train = np.argmax(y_train, axis=-1)
y_train
model = XGBClassifier()
model.fit(x_train[:10000], y_train[:10000])
res2 = model.predict((patches*255).reshape(256*256, 29*29))
len(res2[res2>0])
plt.title('Predicted segmentation with xgboost')
plt.imshow(res2.reshape(256,256))
dice(seg_image, res2.reshape(256,256))